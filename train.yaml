base_model: "mistralai/Mistral-7B-v0.1"
model_type: "MistralForCausalLM"
load_in_4bit: true
trust_remote_code: true

datasets:
  - path: ./analoggenie.jsonl
    type: chat

chat_template: chatml
dataset_prepared_path: ./prepared

output_dir: ./output
logging_dir: ./logs

lora:
  r: 64
  alpha: 16
  dropout: 0.05
  target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]
  bias: "none"
  task_type: "CAUSAL_LM"

per_device_train_batch_size: 4
per_device_eval_batch_size: 4
gradient_accumulation_steps: 8
num_train_epochs: 3
learning_rate: 2e-4
warmup_steps: 100
logging_steps: 10
save_steps: 1000
save_total_limit: 2
evaluation_strategy: "steps"
eval_steps: 500
fp16: true
bf16: false
optim: "adamw_torch"
report_to: ["wandb"]

seed: 42
